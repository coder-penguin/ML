{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_tutorial_gan",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coder-penguin/ML/blob/master/tutorial/keras_tutorial_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-5PkF7PBj7_",
        "colab_type": "text"
      },
      "source": [
        "#Sample code for image generation with GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vtm-2URtR1H",
        "colab_type": "text"
      },
      "source": [
        "Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppbgVaOetTVb",
        "colab_type": "code",
        "outputId": "dea11ef4-fb9b-4bb8-bd96-3c8e9e4f0482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image, ImageOps\n",
        "import subprocess\n",
        "import glob\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Flatten, Conv2D, MaxPooling2D, Reshape, UpSampling2D, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, Callback\n",
        "from tensorflow.keras.utils import plot_model, model_to_dot, to_categorical\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img, img_to_array\n",
        "from tensorflow.keras import backend as K\n",
        "from IPython.display import SVG, clear_output\n",
        "\n",
        "import shutil\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KUCH6wcthEF",
        "colab_type": "code",
        "outputId": "6fb09d71-8da5-43d9-ee43-608b9d7019c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check GPU\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGZMoZsWtG-e",
        "colab_type": "text"
      },
      "source": [
        "Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brHzSiK-tbKW",
        "colab_type": "code",
        "outputId": "397014e1-3369-45e1-c9e7-def40d335ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK5rbyYUti3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/img_extracted.zip' .\n",
        "!unzip -q 'img_extracted.zip'\n",
        "!rm 'img_extracted.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL4-eNN6uDUs",
        "colab_type": "code",
        "outputId": "40c5c934-8a50-419c-830e-b91f9d9a9f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls ./img_extracted"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fake  real\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t09rGoHO8OdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "8c75d58a-ce3d-4887-8557-9555b72f751f"
      },
      "source": [
        "!mv train img_extracted/real/real"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'train': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IHwQiHd7yA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#move only real images\n",
        "!mkdir train\n",
        "!mv img_extracted/real/real train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhgfmaTWV-GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get image names\n",
        "input_directry = './train/real/'\n",
        "images = glob.glob(input_directry+'*.*')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNSwg9Y-gtHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_images(directry, with_title=False):\n",
        "  images = glob.glob(directry+'*.*')\n",
        "  plt.figure(figsize=(28, 12))\n",
        "  for i in range(12):\n",
        "    if i < len(images):\n",
        "      plt.subplot(3, 4, i+1)\n",
        "      img = mpimg.imread(images[i])\n",
        "      imgplot = plt.imshow(img)\n",
        "      plt.axis('off')\n",
        "      if with_title:\n",
        "        plt.title(images[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFvBp4giUuNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show input images\n",
        "show_images(input_directry)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWjy9yhPETE9",
        "colab_type": "text"
      },
      "source": [
        "Set data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxap-Eth8LJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        channel_shift_range=20.0,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNSidXA1z5U",
        "colab_type": "code",
        "outputId": "80c4b29b-1925-4955-c19f-153cadadae64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './train/', #A subdirectory under the directory is required.\n",
        "        target_size=(32, 32),\n",
        "        batch_size=32,\n",
        "        color_mode='grayscale',\n",
        "        class_mode=None)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 270 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDaGgSccEDVO",
        "colab_type": "code",
        "outputId": "2c00fb77-1434-4b54-a14a-e49d1a249dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'real': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvugNRRWNuYH",
        "colab_type": "text"
      },
      "source": [
        "###Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mARArt9k7Zad",
        "colab_type": "text"
      },
      "source": [
        "Three types of losses for GANs\n",
        "\n",
        "There were proposed numerous loss functions to train GANs. In this notebook we have implemented three the most popular choices:\n",
        "\n",
        "`KL`:\n",
        "\n",
        "\n",
        "$$\\mathcal{L}_g = \\log(1 - \\mathrm{discriminator}(\\mathrm{gen}))$$\n",
        "\n",
        "$$\\mathcal{L}_d = - \\log(\\mathrm{discriminator}(\\mathrm{real})) - \\log(1 - \\mathrm{discriminator}(\\mathrm{gen}))$$\n",
        "\n",
        "\n",
        "`REVERSED_KL`\n",
        "\n",
        "$$\\mathcal{L}_g = - \\log(\\mathrm{discriminator}(\\mathrm{gen}))$$\n",
        "\n",
        "$$\\mathcal{L}_d = - \\log(\\mathrm{discriminator}(\\mathrm{real})) - \\log(1 - \\mathrm{discriminator}(\\mathrm{gen}))$$\n",
        "\n",
        "\n",
        "`WASSERSTEIN`\n",
        "\n",
        "$$\\mathcal{L}_g = - \\mathrm{discriminator}(\\mathrm{gen})$$\n",
        "\n",
        "$$\\mathcal{L}_d = \\mathrm{discriminator}(\\mathrm{gen}) - \\mathrm{discriminator}(\\mathrm{real})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP7q3Ao_Ur-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANLosses(object):\n",
        "  def __init__(self, loss_type):\n",
        "    self.loss_type = loss_type\n",
        "   \n",
        "  def d_loss(self, y_real, y_gen):\n",
        "    eps = 1e-10\n",
        "    if self.loss_type in ['KL', 'REVERSED_KL']: \n",
        "      loss = - K.mean(K.log(y_real + eps)) - K.mean(K.log(1 - y_gen + eps))\n",
        "    elif self.loss_type == 'WASSERSTEIN':\n",
        "      loss = - (K.mean(y_real) - K.mean(y_gen))\n",
        "    return loss\n",
        "\n",
        "  def g_loss(self, y_real, y_gen):\n",
        "    eps = 1e-10\n",
        "    if self.loss_type == 'KL': \n",
        "      loss = K.mean(K.log(1 - y_gen + eps))  \n",
        "    elif self.loss_type == 'REVERSED_KL':\n",
        "      loss = - K.mean(K.log(y_gen + eps))\n",
        "    elif self.loss_type == 'WASSERSTEIN':\n",
        "      loss = - K.mean(y_gen)\n",
        "    return loss\n",
        "\n",
        "  def calc_gradient_penalty(self, tape, discriminator, img_gen, img_real, lambda_reg = .1):\n",
        "    #https://arxiv.org/abs/1704.00028\n",
        "    with tape:\n",
        "      alpha = np.random.uniform(size = (img_real.shape[0], 1, 1, 1))\n",
        "      img_interpolates = (alpha * img_real + ((1 - alpha) * img_gen))\n",
        "      y_interpolates = discriminator(img_interpolates)\n",
        "    gradients = tape.gradient(y_interpolates, [img_interpolates])[0]\n",
        "    gradients = K.sqrt(K.sum(K.square(gradients), axis=[1,2,3]))\n",
        "    gradient_penalty = K.mean(K.square(gradients -1)) * lambda_reg\n",
        "    return gradient_penalty\n",
        "    \n",
        "  def calc_zero_centered_gradient_penalty(self, tape, discriminator, img_gen, img_real, gamma_reg = .1):\n",
        "    #https://arxiv.org/abs/1705.09367\n",
        "    with tape:\n",
        "      img_real += img_gen * 0\n",
        "      y_real = discriminator(img_real)\n",
        "    gradients = tape.gradient(y_real, [img_real])[0]\n",
        "    gradients = K.sqrt(K.sum(K.square(gradients), axis=[1,2,3]))\n",
        "    zc_gradient_penalty = gamma_reg / 2 * K.mean(K.square(gradients))\n",
        "    \n",
        "    return zc_gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZw7woUhR1xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN(object):\n",
        "  def __init__(self, discriminator, generator, optimizer_d, optimizer_g, noise_dim, k_d=10, k_g=1, \n",
        "                 loss_type='KL', penalty=None, instance_noise=False, lipschitz_weights=False, clip_lower=-0.1, clip_upper=0.1, verbose=0):\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.noise_dim = noise_dim\n",
        "    self.k_d = k_d\n",
        "    self.k_g = k_g\n",
        "    self.ganlosses = GANLosses(loss_type)\n",
        "    self.penalty = penalty #GRAD, ZERO_CENTERED_GRAD \n",
        "    self.instance_noise = instance_noise \n",
        "    self.lipschitz_weights = lipschitz_weights\n",
        "    self.clip_lower = clip_lower\n",
        "    self.clip_upper = clip_upper\n",
        "\n",
        "    #compile discriminator\n",
        "    self.discriminator.compile(loss=self.ganlosses.d_loss, optimizer=optimizer_d) #is trainable\n",
        "    print('discminator was sucessfully compiled!')\n",
        "\n",
        "    #compile combined model\n",
        "    self.discriminator.trainable = False #discriminator in the combined model must not be trainable\n",
        "    self.combined = Sequential([self.generator, self.discriminator], name='combined')\n",
        "    self.combined.compile(loss=self.ganlosses.g_loss, optimizer=optimizer_g)\n",
        "    print('generator was sucessfully compiled!')\n",
        "\n",
        "    self.discriminator.trainable = True #need to be True to get trainable_weights\n",
        "\n",
        "    if verbose == 1 :\n",
        "      self.discriminator.summary()\n",
        "      self.combined.summary()\n",
        "\n",
        "  def fit(self, dataset=None, epochs=1, steps_per_epoch=1, sample_interval=50):\n",
        "    \n",
        "    dis_loss_epochs= []\n",
        "    gen_loss_epochs = []\n",
        "    real_accuracy_epochs = [] \n",
        "    generated_accuracy_epochs = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      dis_loss = 0\n",
        "      gen_loss = 0\n",
        "      real_accuracy = Accuracy()\n",
        "      generated_accuracy = Accuracy()\n",
        "      \n",
        "      for step, img_data in enumerate(dataset):\n",
        "        if step == steps_per_epoch:\n",
        "          break\n",
        "                \n",
        "        # Optimize D\n",
        "        for _ in range(self.k_d):\n",
        "          img_b = img_data * 2 - 1. #[0, 1] --> [-1, 1]\n",
        "          noise = np.random.randn(len(img_b), self.noise_dim)\n",
        "\n",
        "          if self.instance_noise :\n",
        "            img_b = self.add_instance_noise(img_b)\n",
        "\n",
        "          with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            y_b = self.discriminator(img_b)\n",
        "            img_gen = self.combined.layers[0](noise)\n",
        "            if self.instance_noise:\n",
        "              img_gen = self.add_instance_noise(img_gen)\n",
        "            y_gen = self.combined.layers[1](img_gen)\n",
        "            loss = self.discriminator.loss(y_b, y_gen)\n",
        "          \n",
        "          #caluculate penalty\n",
        "          if self.penalty == 'GRAD':\n",
        "            grad_penalty = self.ganlosses.calc_gradient_penalty(tape2, self.discriminator, img_gen, img_b)  \n",
        "            with tape1:   \n",
        "              loss += grad_penalty           \n",
        "          elif self.penalty == 'ZERO_CENTERED_GRAD':\n",
        "            grad_penalty = self.ganlosses.calc_zero_centered_gradient_penalty(tape2, self.discriminator, img_gen, img_b)\n",
        "            with tape1:   \n",
        "              loss -= grad_penalty\n",
        "          \n",
        "          #update weights manually\n",
        "          gradients = tape1.gradient(loss, self.discriminator.trainable_weights)\n",
        "          self.discriminator.optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_weights))\n",
        "\n",
        "          if self.lipschitz_weights :                    \n",
        "            for layer in self.discriminator.layers:\n",
        "              weights = layer.get_weights()\n",
        "              weights = [np.clip(w, self.clip_lower, self.clip_upper) for w in weights]\n",
        "              layer.set_weights(weights)\n",
        "\n",
        "        dis_loss += loss\n",
        "\n",
        "        # Optimize G\n",
        "        for _ in range(self.k_g):\n",
        "          img_b = img_data * 2 - 1. #[0, 1] --> [-1, 1]\n",
        "          noise = np.random.randn(len(img_b), self.noise_dim)\n",
        "\n",
        "          if self.instance_noise:\n",
        "            img_b = self.add_instance_noise(img_b)\n",
        "\n",
        "          #get loss\n",
        "          with tf.GradientTape() as tape:\n",
        "            y_b = self.discriminator(img_b)\n",
        "            if self.instance_noise:\n",
        "              img_gen = self.combined.layers[0](noise)\n",
        "              img_gen = self.add_instance_noise(img_gen)\n",
        "              y_gen = self.combined.layers[1](img_gen)\n",
        "            else:\n",
        "              y_gen = self.combined(noise)\n",
        "            loss = self.combined.loss(y_b, y_gen)\n",
        "  \n",
        "          #update weights manually\n",
        "          gradients = tape.gradient(loss, self.combined.trainable_weights)\n",
        "          self.combined.optimizer.apply_gradients(zip(gradients, self.combined.trainable_weights))\n",
        "\n",
        "        gen_loss += loss\n",
        "\n",
        "        # update accuracy\n",
        "        #accuracy for real images\n",
        "        y_pred = [1 if y_b[i]>0.5 else 0 for i in range(len(y_b))]\n",
        "        y_true = [1 for _ in range(len(y_b))] \n",
        "        real_accuracy.update_state(y_true, y_pred)\n",
        "\n",
        "        #accuracy for generated images\n",
        "        y_pred = [1 if y_gen[i]>0.5 else 0 for i in range(len(y_gen))]\n",
        "        y_true = [0 for _ in range(len(y_gen))]       \n",
        "        generated_accuracy.update_state(y_true, y_pred)     \n",
        "\n",
        "      dis_loss /= steps_per_epoch\n",
        "      gen_loss /= steps_per_epoch\n",
        "\n",
        "      dis_loss_epochs.append(dis_loss)\n",
        "      gen_loss_epochs.append(gen_loss)\n",
        "      real_accuracy_epochs.append(real_accuracy.result().numpy())\n",
        "      generated_accuracy_epochs.append(generated_accuracy.result().numpy())\n",
        "\n",
        "      clear_output()\n",
        "      plt.figure(figsize=(12, 12))\n",
        "      plt.plot(dis_loss_epochs, label='dis_loss')\n",
        "      plt.plot(gen_loss_epochs, label='gen_loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "        \n",
        "      plt.figure(figsize=(12, 12))\n",
        "      plt.plot(real_accuracy_epochs, label='real_accuracy')\n",
        "      plt.plot(generated_accuracy_epochs, label='generated_accuracy')\n",
        "      plt.plot()\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n",
        "      #print(dis_loss, gen_loss)\n",
        "\n",
        "      if epoch % sample_interval == 0:\n",
        "        self.sample_images(epoch)\n",
        "  \n",
        "  def add_instance_noise(self, data, std=0.01):\n",
        "    # https://arxiv.org/abs/1610.04490\n",
        "    return data + np.random.normal(0, std, size=data.shape)\n",
        "\n",
        "  def sample_images(self, epoch):\n",
        "    row, column = 3, 4\n",
        "    noise = np.random.randn(row * column, self.noise_dim)\n",
        "    gen_imgs = self.combined.layers[0](noise)   \n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5 # Rescale images [-1, 1] --> [0, 1]\n",
        "\n",
        "    plt.figure(figsize=(28, 12))\n",
        "    fig, axs = plt.subplots(row, column)\n",
        "    count = 0\n",
        "    for i in range(row):\n",
        "      for j in range(column):\n",
        "        axs[i,j].imshow(gen_imgs[count, :,:,0], cmap='gray')\n",
        "        axs[i,j].axis('off')\n",
        "        count += 1\n",
        "\n",
        "    if not os.path.exists('images'): \n",
        "      subprocess.call('mkdir images', shell=True)\n",
        "    fig.savefig('images/images_epoch%d.png' % epoch)\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3caPEEIKCHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator():\n",
        "  activation = 'elu'\n",
        "  model = Sequential([\n",
        "    Conv2D(32,3, input_shape=(32, 32, 1)),#filters, kernel_size\n",
        "    Activation(activation),\n",
        "    #MaxPooling2D(pool_size=4),\n",
        "    Conv2D(64,3),\n",
        "    Activation(activation),\n",
        "    MaxPooling2D(pool_size=4),\n",
        "    Dropout(0.2),\n",
        "    #Conv2D(64,3),\n",
        "    #Activation(activation),\n",
        "    #MaxPooling2D(pool_size=4),\n",
        "    #Dropout(0.2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    BatchNormalization(),\n",
        "    Activation(activation),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation=activation),\n",
        "    Dense(1, activation='sigmoid')\n",
        "  ], name='discriminator')\n",
        "\n",
        "  #do not compile this here\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es6VLT1LubgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(noise_dim):\n",
        "  activation = 'elu'\n",
        "  model = Sequential([\n",
        "    Dense(8 * 8 * 128, input_dim=noise_dim),\n",
        "    Activation(activation),\n",
        "    Reshape((8, 8, 128)),\n",
        "    UpSampling2D(),\n",
        "    Conv2D(128, kernel_size=4, padding='same'),\n",
        "    BatchNormalization(momentum=0.8),\n",
        "    Activation(activation),\n",
        "    UpSampling2D(),\n",
        "    Conv2D(64, kernel_size=4, padding='same'),\n",
        "    BatchNormalization(momentum=0.8),\n",
        "    Activation(activation),\n",
        "    Conv2D(1, kernel_size=4, padding='same'),#gray-scale\n",
        "    Activation('tanh')\n",
        "  ], name='generator')\n",
        "\n",
        "  #do not compile this here\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "706d6f58-eb11-40e0-857d-c7cf90e09782",
        "id": "VA2BBN4s_WLZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "noise_dim = 100\n",
        "optimizer_d = SGD(lr=0.005, nesterov=True)\n",
        "optimizer_g = SGD(lr=0.005, nesterov=True)\n",
        "discriminator = build_discriminator()\n",
        "generator = build_generator(noise_dim)\n",
        "gan = GAN(discriminator, generator, optimizer_d, optimizer_g, noise_dim, k_d=5, instance_noise=True)\n",
        "#gan = GAN(discriminator, generator, optimizer_d, optimizer_g, noise_dim, k_d=3, instance_noise=True, loss_type='WASSERSTEIN', penalty='GRAD')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "discminator was sucessfully compiled!\n",
            "generator was sucessfully compiled!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rdgvzxl1Kdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.fit(train_generator, epochs=1000, steps_per_epoch=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulyGSSBYOId8",
        "colab_type": "text"
      },
      "source": [
        "###Show generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQc8grkmMHWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6887ca1-ab1b-4fe0-ef14-f5e0fd3f0086"
      },
      "source": [
        "sample_epoch = 10\n",
        "gan.sample_images(sample_epoch)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x864 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFdD-x1ZKZ3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = glob.glob('./images/*.*')\n",
        "plt.figure(figsize=(12, 8))\n",
        "img = mpimg.imread('./images/images_epoch%d.png'%sample_epoch)\n",
        "imgplot = plt.imshow(img)\n",
        "plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F-zfxit8R0A",
        "colab_type": "text"
      },
      "source": [
        "###Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmZQtZYZ6yAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model\n",
        "disc_filename = '/content/drive/My Drive/discriminator.h5'\n",
        "gan.discriminator.save(disc_filename)\n",
        "gen_filename = '/content/drive/My Drive/generator.h5'\n",
        "gan.generator.save(gen_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsKpVKzbds33",
        "colab_type": "code",
        "outputId": "bc318e47-cf44-4a99-c634-67a0c378f6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "!zip -r /content/gan_images.zip ./images"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: images/ (stored 0%)\n",
            "  adding: images/images_epoch10.png (deflated 6%)\n",
            "  adding: images/images_epoch0.png (deflated 5%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLMOXhEpefTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('./gan_images.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrEilf6AeqQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}